{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import loading, Spark\n",
    "from src.memory_based import Memory_based_CF\n",
    "import pyspark.ml as M\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI address http://127.0.0.1:4040\n"
     ]
    }
   ],
   "source": [
    "spark = Spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = loading(spark, '../data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = datas['train_0.75_0.25'], datas['test_0.75_0.25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: string, movieId: string, rating: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline():\n",
    "    def __init__(self, usercol='userId', itemcol='movieId', ratingcol='rating'):\n",
    "        self.usercol = usercol\n",
    "        self.itemcol = itemcol\n",
    "        self.ratingcol = ratingcol\n",
    "    \n",
    "    def fit(self, X):\n",
    "        train = self._preprocess(X)\n",
    "        umean = train.groupby(self.usercol).agg(F.mean(self.ratingcol).alias('umean'))\n",
    "        imean = train.groupby(self.itemcol).agg(F.mean(self.ratingcol).alias('imean'))\n",
    "        \n",
    "        self.umean = umean\n",
    "        self.imean = imean\n",
    "        \n",
    "    def predict(self, X):\n",
    "        test = self._preprocess(X)\n",
    "        \n",
    "        pred = test.join(self.umean, test[self.usercol] == self.umean[self.usercol])\\\n",
    "                   .select(test[self.usercol], test[self.itemcol], self.umean.umean)\n",
    "        pred = pred.join(self.imean, pred[self.itemcol] == self.imean[self.itemcol])\\\n",
    "                   .select(pred[self.usercol], pred[self.itemcol], pred.umean, self.imean.imean)\n",
    "        \n",
    "        pred = pred.select(pred[self.usercol], pred[self.itemcol],\n",
    "                           ((F.col('umean') + F.col('imean'))/2).alias('prediction'))\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _preprocess(self, _X):\n",
    "        \"\"\"[preprocess the input dataset]\n",
    "\n",
    "        Args:\n",
    "            _X (Pyspark DataFrame): [the training or test set]\n",
    "\n",
    "        Returns:\n",
    "            Pyspark DataFrame: [the preprocessed DataFrame]\n",
    "        \"\"\"        \n",
    "        cast_int = lambda df: df.select([F.col(c).cast('int') for c in [self.usercol, self.itemcol]] + \\\n",
    "                                [F.col(self.ratingcol).cast('float')])\n",
    "        return cast_int(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalization",
   "language": "python",
   "name": "personalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
