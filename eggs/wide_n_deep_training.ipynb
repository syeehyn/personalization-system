{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ds-personalization/final-project-qrdecomposition_final/blob/main/notebook/wide_n_deep_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GaAwbZEXB19R"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = os.path.join('../','downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M7IVlfT3Aoz_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "###utilities\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "###numpy,scipy,pandas,sklearn stacks\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "###torch stacks\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_widedeep.preprocessing import DensePreprocessor\n",
    "from pytorch_widedeep.callbacks import (\n",
    "    LRHistory,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_widedeep.optim import RAdam\n",
    "from pytorch_widedeep.initializers import XavierNormal, KaimingNormal\n",
    "from pytorch_widedeep.models import Wide, DeepDense, WideDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "jB1Q-EZUAoz_"
   },
   "outputs": [],
   "source": [
    "class wide_deep():\n",
    "    def __init__(self,wide_cols='genres',\n",
    "                    deep_cols=['userId', 'movieId'],\n",
    "                    target_col = 'rating',\n",
    "                    deep_embs=[64, 64],\n",
    "                    deep_hidden=[64,32,16],\n",
    "                    deep_dropout=[0.1, 0.1, .1],\n",
    "                    deep_bachnorm=True):\n",
    "        self.wide = None\n",
    "        self.deep = None\n",
    "        self.deep_hidden = deep_hidden\n",
    "        self.deep_dropout = deep_dropout\n",
    "        self.deep_bachnorm = deep_bachnorm\n",
    "        self.model = None\n",
    "\n",
    "        self.embs = [(col, dim) for col, dim in zip(deep_cols, deep_embs)]\n",
    "        self.wide_preprocessor = self._genre_preprocessor(wide_cols)\n",
    "        self.deep_preprocessor = DensePreprocessor(embed_cols=self.embs)\n",
    "        self.target_col = target_col\n",
    "\n",
    "\n",
    "    def fit(self, train, n_epochs=10, batch_size=128, val_split=.1, verbose = True):\n",
    "        X, y = train.drop(self.target_col, axis = 1), train[self.target_col].values\n",
    "        wide_feature = self.wide_preprocessor.fit_transform(X)\n",
    "        deep_feature = self.deep_preprocessor.fit_transform(X)\n",
    "        self.wide = Wide(wide_dim=np.unique(wide_feature).shape[0], pred_dim=1)\n",
    "        self.deep = DeepDense(hidden_layers=self.deep_hidden, dropout=self.deep_dropout,\n",
    "                      batchnorm=self.deep_bachnorm,\n",
    "                      deep_column_idx=self.deep_preprocessor.deep_column_idx,\n",
    "                      embed_input=self.deep_preprocessor.embeddings_input)\n",
    "        self.model =  WideDeep(wide=self.wide, deepdense=self.deep)\n",
    "        wide_opt = torch.optim.Adam(self.model.wide.parameters(), lr=0.01)\n",
    "        deep_opt = RAdam(self.model.deepdense.parameters())\n",
    "        wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=3)\n",
    "        deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=5)\n",
    "        callbacks = [\n",
    "                        LRHistory(n_epochs=n_epochs),\n",
    "                        EarlyStopping(patience=5),\n",
    "                        ModelCheckpoint(filepath=\"model_weights/wd_out\"),\n",
    "                    ]\n",
    "        optimizers = {\"wide\": wide_opt, \"deepdense\": deep_opt}\n",
    "        schedulers = {\"wide\": wide_sch, \"deepdense\": deep_sch}\n",
    "        initializers = {\"wide\": KaimingNormal, \"deepdense\": XavierNormal}\n",
    "        self.model.compile(method='regression',\n",
    "                            optimizers=optimizers,\n",
    "                        lr_schedulers=schedulers,\n",
    "                        initializers=initializers,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=verbose)\n",
    "        self.model.fit(X_wide=wide_feature, \n",
    "                  X_deep=deep_feature, \n",
    "                  target=y, \n",
    "                  n_epochs=n_epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  val_split=val_split,)\n",
    "    def load_pretrained(self, train, fp, device):\n",
    "        X = train.copy()\n",
    "        wide_feature = self.wide_preprocessor.fit_transform(X)\n",
    "        deep_feature = self.deep_preprocessor.fit_transform(X)\n",
    "        self.wide = Wide(wide_dim=np.unique(wide_feature).shape[0], pred_dim=1)\n",
    "        self.deep = DeepDense(hidden_layers=self.deep_hidden, dropout=self.deep_dropout,\n",
    "                      batchnorm=self.deep_bachnorm,\n",
    "                      deep_column_idx=self.deep_preprocessor.deep_column_idx,\n",
    "                      embed_input=self.deep_preprocessor.embeddings_input)\n",
    "        self.model =  torch.load(fp,  map_location=torch.device(device))\n",
    "        \n",
    "    def predict(self, test):\n",
    "        X = test.copy()\n",
    "        wide_feature = self.wide_preprocessor.transform(X)\n",
    "        deep_feature = self.deep_preprocessor.transform(X)\n",
    "        return self.model.predict(X_wide=wide_feature, X_deep=deep_feature)\n",
    "\n",
    "    def _genre_preprocessor(self, genre_feat):\n",
    "        dense_layer = lambda X: X.toarray()\n",
    "        genre_transformer = Pipeline(steps=[\n",
    "                ('tokenizer', CountVectorizer()),\n",
    "                ('dense', FunctionTransformer(dense_layer, validate=False))   \n",
    "        ])\n",
    "        preproc = ColumnTransformer(transformers=[('genre', genre_transformer, genre_feat),])\n",
    "        return preproc\n",
    "\n",
    "\n",
    "    def _deep_preprocessor(self,embs):\n",
    "        return DensePreprocessor(embed_cols=embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ebdcwoxpAo0A"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Uy9-7B-JAo0A"
   },
   "outputs": [],
   "source": [
    "wd = wide_deep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDf24w-xAo0A",
    "outputId": "a6746e87-c3ab-4c8c-b13b-0a90d6f834f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/22894 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 22894/22894 [04:00<00:00, 95.21it/s, loss=41.4]   \n",
      "valid: 100%|██████████| 2544/2544 [00:16<00:00, 157.81it/s, loss=0.88] \n",
      "epoch 2: 100%|██████████| 22894/22894 [04:00<00:00, 95.18it/s, loss=1.2]  \n",
      "valid: 100%|██████████| 2544/2544 [00:16<00:00, 156.65it/s, loss=0.694]\n",
      "epoch 3: 100%|██████████| 22894/22894 [04:19<00:00, 88.38it/s, loss=0.676] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 161.71it/s, loss=0.669]\n",
      "epoch 4: 100%|██████████| 22894/22894 [04:32<00:00, 83.90it/s, loss=0.63]  \n",
      "valid: 100%|██████████| 2544/2544 [00:17<00:00, 145.83it/s, loss=0.671]\n",
      "epoch 5: 100%|██████████| 22894/22894 [04:06<00:00, 92.92it/s, loss=0.604] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 159.64it/s, loss=0.668]\n",
      "epoch 6: 100%|██████████| 22894/22894 [04:26<00:00, 85.84it/s, loss=0.604] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 161.17it/s, loss=0.646]\n",
      "epoch 7: 100%|██████████| 22894/22894 [04:16<00:00, 89.35it/s, loss=0.592] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 166.68it/s, loss=0.642]\n",
      "epoch 8: 100%|██████████| 22894/22894 [04:33<00:00, 83.86it/s, loss=0.587] \n",
      "valid: 100%|██████████| 2544/2544 [00:16<00:00, 155.53it/s, loss=0.639]\n",
      "epoch 9: 100%|██████████| 22894/22894 [04:12<00:00, 90.53it/s, loss=0.582] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 161.73it/s, loss=0.638]\n",
      "epoch 10: 100%|██████████| 22894/22894 [04:15<00:00, 89.69it/s, loss=0.577] \n",
      "valid: 100%|██████████| 2544/2544 [00:15<00:00, 161.07it/s, loss=0.639]\n"
     ]
    }
   ],
   "source": [
    "wd.fit(sample_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXZG6HTgTveK",
    "outputId": "03532ec3-74c6-4c43-8e51-e7b03099aa66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 25437/25437 [01:38<00:00, 257.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pred = wd.predict(sample_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIJgtwGnTorg",
    "outputId": "607d492c-b40b-4eaf-b0f1-8c6253704847"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 8473/8473 [00:39<00:00, 216.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred = wd.predict(sample_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AakSrV7QAo0B"
   },
   "outputs": [],
   "source": [
    "torch.save(wd.model, os.path.join('../trained_model', \"wide_deep_sample.t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lWQMKrA-ZwOk"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('../model_results', \"wide_deep_sample_train_pred.npy\"), 'wb') as f:\n",
    "    np.save(f, train_pred)\n",
    "with open(os.path.join('../model_results', \"wide_deep_sample_test_pred.npy\"), 'wb') as f:\n",
    "    np.save(f, test_pred)\n",
    "with open(os.path.join('../model_results', \"wide_deep_sample_train_true.npy\"), 'wb') as f:\n",
    "    np.save(f, sample_train_df.rating.values)\n",
    "with open(os.path.join('../model_results', \"wide_deep_sample_test_true.npy\"), 'wb') as f:\n",
    "    np.save(f, sample_test_df.rating.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "wide_n_deep_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
