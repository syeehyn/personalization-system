{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IEOR 4571 Fall 2020 Homework2 Report**\n",
    "\n",
    "\n",
    "- Hu, Bo (uni: bh2569)\n",
    "- Qin, Rui (uni: rq217)\n",
    "- Yuan, Shuibenyang (uni: sy2938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo how did we sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import loading, Spark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI address http://127.0.0.1:4040\n"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "spark = Spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data from '/data/raw/sample.csv'\n",
    "datas = loading(spark, '../data/raw')\n",
    "sample = datas['sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "            number of data points in the sample: {sample.count()},\n",
    "            number of unique users in the sample: {sample.select('userId').distinct().count()},\n",
    "            number of unique movies in the sample: {sample.select('movieId').distinct().count()},\n",
    "            mean of number of movies a user rated:{sample.groupby('userId').agg(F.count('movieId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            mean of number of users a movie be rated: {sample.groupby('movieId').agg(F.count('userId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            average rating: {sample.select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating: {sample.select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by user: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by user mean: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by movie: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by movie mean: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Evaluator, Cross_validate_als\n",
    "from src.model_based import Als\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = loading(spark, '../data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(splits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build evaluation pipeline\n",
    "def evaluate(train, test, evaluators, model):\n",
    "    print('training')\n",
    "    start = time.time()\n",
    "    model.fit(train)\n",
    "    end = time.time()\n",
    "    print(f'training time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing train set')\n",
    "    start = time.time()\n",
    "    train_pred = model.predict(train)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing test set')\n",
    "    start = time.time()\n",
    "    test_pred = model.predict(test)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    res = pd.DataFrame(np.zeros((len(evaluators),2)), columns = ['train', 'test'], index = evaluators.keys())\n",
    "    for eva in evaluators.keys():\n",
    "        res.loc[eva, 'train'] = evaluators[eva].evaluate(train_pred)\n",
    "        res.loc[eva, 'test'] = evaluators[eva].evaluate(test_pred)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {'rmse': Evaluator(metrics = 'rmse'), \n",
    "              'accuracy': Evaluator(metrics = 'accuracy'), \n",
    "              'coverage_2': Evaluator(metrics = 'converage_k', \n",
    "                                       ratingCol='rating', \n",
    "                                       predCol='prediction', \n",
    "                                       idCol='userId', \n",
    "                                       k=2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.memory_based import Memory_based_CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 37.99 seconds\n",
      "inferencing train set\n",
      "inference time: 11.17 seconds\n",
      "inferencing test set\n",
      "inference time: 3.86 seconds\n",
      "training\n",
      "training time: 31.22 seconds\n",
      "inferencing train set\n",
      "inference time: 7.7 seconds\n",
      "inferencing test set\n",
      "inference time: 7.34 seconds\n",
      "training\n",
      "training time: 26.34 seconds\n",
      "inferencing train set\n",
      "inference time: 3.85 seconds\n",
      "inferencing test set\n",
      "inference time: 9.92 seconds\n",
      "CPU times: user 3min 46s, sys: 25.7 s, total: 4min 12s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ub_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ub_CF_res = ub_CF_res.append(i)\n",
    "ub_CF_res = ub_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.822981</td>\n",
       "      <td>0.882472</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.737826</td>\n",
       "      <td>0.705916</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.931907</td>\n",
       "      <td>0.707219</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.812562</td>\n",
       "      <td>0.903506</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.744819</td>\n",
       "      <td>0.695154</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.880891</td>\n",
       "      <td>0.861922</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.789096</td>\n",
       "      <td>0.961355</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.761302</td>\n",
       "      <td>0.674534</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.734384</td>\n",
       "      <td>0.920091</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.822981  0.882472  0.75_0.25\n",
       "accuracy    0.737826  0.705916  0.75_0.25\n",
       "coverage_2  0.931907  0.707219  0.75_0.25\n",
       "rmse        0.812562  0.903506    0.5_0.5\n",
       "accuracy    0.744819  0.695154    0.5_0.5\n",
       "coverage_2  0.880891  0.861922    0.5_0.5\n",
       "rmse        0.789096  0.961355  0.25_0.75\n",
       "accuracy    0.761302  0.674534  0.25_0.75\n",
       "coverage_2  0.734384  0.920091  0.25_0.75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_CF_res.to_csv('../data/processed/ub_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 6.08 seconds\n",
      "inferencing train set\n",
      "inference time: 10.81 seconds\n",
      "inferencing test set\n",
      "inference time: 4.01 seconds\n",
      "training\n",
      "training time: 5.71 seconds\n",
      "inferencing train set\n",
      "inference time: 7.41 seconds\n",
      "inferencing test set\n",
      "inference time: 6.94 seconds\n",
      "training\n",
      "training time: 4.19 seconds\n",
      "inferencing train set\n",
      "inference time: 3.73 seconds\n",
      "inferencing test set\n",
      "inference time: 10.19 seconds\n",
      "CPU times: user 55.1 s, sys: 1.77 s, total: 56.9 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ib_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ib_CF_res = ib_CF_res.append(i)\n",
    "ib_CF_res = ib_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.852612</td>\n",
       "      <td>0.854921</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.723621</td>\n",
       "      <td>0.722746</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.910622</td>\n",
       "      <td>0.691240</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.876476</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.717357</td>\n",
       "      <td>0.714118</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.865931</td>\n",
       "      <td>0.840369</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.919891</td>\n",
       "      <td>0.935865</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.707726</td>\n",
       "      <td>0.697115</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.736767</td>\n",
       "      <td>0.898118</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.852612  0.854921  0.75_0.25\n",
       "accuracy    0.723621  0.722746  0.75_0.25\n",
       "coverage_2  0.910622  0.691240  0.75_0.25\n",
       "rmse        0.876075  0.876476    0.5_0.5\n",
       "accuracy    0.717357  0.714118    0.5_0.5\n",
       "coverage_2  0.865931  0.840369    0.5_0.5\n",
       "rmse        0.919891  0.935865  0.25_0.75\n",
       "accuracy    0.707726  0.697115  0.25_0.75\n",
       "coverage_2  0.736767  0.898118  0.25_0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_CF_res.to_csv('../data/processed/ib_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Matrix Factorization Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Cross_validate_als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"regParam\": [0.01, 0.05, 0.1, 0.15],\n",
    "    \"rank\": [10, 50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "cf = cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:31<00:00, 34.58s/it]\n",
      "100%|██████████| 20/20 [09:29<00:00, 28.46s/it]\n",
      "100%|██████████| 20/20 [06:39<00:00, 19.95s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = Cross_validate_als(training = train,\n",
    "                            test= test,\n",
    "                            valid_ratio = .1,\n",
    "                            regParam = parameters['regParam'],\n",
    "                            rank = parameters['rank'],\n",
    "                            seed = 0,\n",
    "                            evaluators = list(evaluators.values()))\n",
    "    result.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_parameter_tuning = pd.DataFrame(columns = ['rmse', 'accuracy', 'converage_k'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_parameter_tuning = als_parameter_tuning.append(i)\n",
    "als_parameter_tuning = als_parameter_tuning.dropna()\n",
    "als_parameter_tuning.index.name = '(regParam, rank)'\n",
    "als_parameter_tuning.to_csv('../data/processed/als_parameter_tuning.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameter for each split and metric is\n",
      "best param for accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: rmse, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for rmse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for coverage_k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'the best parameter for each split and metric is')\n",
    "print(f'best param for accuracy')\n",
    "display(als_cv_res.groupby('split').rmse.apply(lambda x: x.idxmin()))\n",
    "print(f'best param for rmse')\n",
    "display(als_cv_res.groupby('split').accuracy.apply(lambda x: x.idxmax()))\n",
    "print(f'best param for coverage_k')\n",
    "display(als_cv_res.groupby('split').accuracy.apply(lambda x: x.idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the best parameter regParam = .15, rank = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_based import Als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 1.87 seconds\n",
      "inferencing train set\n",
      "inference time: 0.01 seconds\n",
      "inferencing test set\n",
      "inference time: 0.02 seconds\n",
      "training\n",
      "training time: 1.78 seconds\n",
      "inferencing train set\n",
      "inference time: 0.01 seconds\n",
      "inferencing test set\n",
      "inference time: 0.02 seconds\n",
      "training\n",
      "training time: 1.4 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.01 seconds\n",
      "CPU times: user 92.8 ms, sys: 22 ms, total: 115 ms\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "als_cf_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_cf_res = als_cf_res.append(i)\n",
    "als_cf_res = als_cf_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_cf_res.to_csv('../data/processed/als_result.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.708663</td>\n",
       "      <td>0.868133</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.746797</td>\n",
       "      <td>0.670438</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.906212</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.658669</td>\n",
       "      <td>0.910945</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.766557</td>\n",
       "      <td>0.649448</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.844469</td>\n",
       "      <td>0.800571</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.550226</td>\n",
       "      <td>1.010943</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.805711</td>\n",
       "      <td>0.609509</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.690452</td>\n",
       "      <td>0.850068</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.708663  0.868133  0.75_0.25\n",
       "accuracy    0.746797  0.670438  0.75_0.25\n",
       "coverage_2  0.906212  0.658363  0.75_0.25\n",
       "rmse        0.658669  0.910945    0.5_0.5\n",
       "accuracy    0.766557  0.649448    0.5_0.5\n",
       "coverage_2  0.844469  0.800571    0.5_0.5\n",
       "rmse        0.550226  1.010943  0.25_0.75\n",
       "accuracy    0.805711  0.609509  0.25_0.75\n",
       "coverage_2  0.690452  0.850068  0.25_0.75"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_cf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalization",
   "language": "python",
   "name": "personalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
