{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IEOR 4571 Fall 2020 Homework2 Report**\n",
    "\n",
    "\n",
    "- Hu, Bo (uni: bh2569)\n",
    "- Qin, Rui (uni: rq217)\n",
    "- Yuan, Shuibenyang (uni: sy2938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo how did we sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import loading, Spark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI address http://127.0.0.1:4040\n"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "spark = Spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data from '/data/raw/sample.csv'\n",
    "datas = loading(spark, '../data/raw')\n",
    "sample = datas['sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            number of data points in the sample: 444289,\n",
      "            number of unique users in the sample: 20000,\n",
      "            number of unique movies in the sample: 1000,\n",
      "            mean of number of movies a user rated:22.21445,\n",
      "            mean of number of users a movie be rated: 444.289,\n",
      "            average rating: 3.562069958968149,\n",
      "            standard deviation of rating: 1.0467842419621054,\n",
      "            average rating by user: 3.685826601448731,\n",
      "            standard deviation of rating by user mean: 0.5225862364055156,\n",
      "            average rating by movie: 3.290922029378176,\n",
      "            standard deviation of rating by movie mean: 0.5133362661920545\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "            number of data points in the sample: {sample.count()},\n",
    "            number of unique users in the sample: {sample.select('userId').distinct().count()},\n",
    "            number of unique movies in the sample: {sample.select('movieId').distinct().count()},\n",
    "            mean of number of movies a user rated:{sample.groupby('userId').agg(F.count('movieId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            mean of number of users a movie be rated: {sample.groupby('movieId').agg(F.count('userId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            average rating: {sample.select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating: {sample.select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by user: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by user mean: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by movie: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by movie mean: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Evaluator, Cross_validate_als\n",
    "from src.model_based import Als\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = loading(spark, '../data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_0.5_0.5', 'train_0.25_0.75', 'test_0.5_0.5', 'test_0.25_0.75', 'train_0.75_0.25', 'test_0.75_0.25']\n"
     ]
    }
   ],
   "source": [
    "print(list(splits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build evaluation pipeline\n",
    "def evaluate(train, test, evaluators, model):\n",
    "    print('training')\n",
    "    start = time.time()\n",
    "    model.fit(train)\n",
    "    end = time.time()\n",
    "    print(f'training time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing train set')\n",
    "    start = time.time()\n",
    "    train_pred = model.predict(train)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing test set')\n",
    "    start = time.time()\n",
    "    test_pred = model.predict(test)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    res = pd.DataFrame(np.zeros((len(evaluators),2)), columns = ['train', 'test'], index = evaluators.keys())\n",
    "    for eva in evaluators.keys():\n",
    "        res.loc[eva, 'train'] = evaluators[eva].evaluate(train_pred)\n",
    "        res.loc[eva, 'test'] = evaluators[eva].evaluate(test_pred)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {'rmse': Evaluator(metrics = 'rmse'), \n",
    "              'accuracy': Evaluator(metrics = 'accuracy'), \n",
    "              'coverage_2': Evaluator(metrics = 'converage_k', \n",
    "                                       ratingCol='rating', \n",
    "                                       predCol='prediction', \n",
    "                                       idCol='userId', \n",
    "                                       k=2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.memory_based import Memory_based_CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 36.35 seconds\n",
      "inferencing train set\n",
      "inference time: 10.29 seconds\n",
      "inferencing test set\n",
      "inference time: 3.45 seconds\n",
      "training\n",
      "training time: 33.57 seconds\n",
      "inferencing train set\n",
      "inference time: 7.38 seconds\n",
      "inferencing test set\n",
      "inference time: 7.22 seconds\n",
      "training\n",
      "training time: 30.88 seconds\n",
      "inferencing train set\n",
      "inference time: 4.02 seconds\n",
      "inferencing test set\n",
      "inference time: 9.8 seconds\n",
      "CPU times: user 3min 48s, sys: 29 s, total: 4min 17s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ub_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ub_CF_res = ub_CF_res.append(i)\n",
    "ub_CF_res = ub_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.821108</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.740528</td>\n",
       "      <td>0.695890</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.939207</td>\n",
       "      <td>0.635700</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.808453</td>\n",
       "      <td>0.921639</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.752306</td>\n",
       "      <td>0.684291</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.911012</td>\n",
       "      <td>0.861449</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.784599</td>\n",
       "      <td>0.980886</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.773132</td>\n",
       "      <td>0.662165</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.817527</td>\n",
       "      <td>0.908271</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.821108  0.894580  0.75_0.25\n",
       "accuracy    0.740528  0.695890  0.75_0.25\n",
       "coverage_2  0.939207  0.635700  0.75_0.25\n",
       "rmse        0.808453  0.921639    0.5_0.5\n",
       "accuracy    0.752306  0.684291    0.5_0.5\n",
       "coverage_2  0.911012  0.861449    0.5_0.5\n",
       "rmse        0.784599  0.980886  0.25_0.75\n",
       "accuracy    0.773132  0.662165  0.25_0.75\n",
       "coverage_2  0.817527  0.908271  0.25_0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_CF_res.to_csv('../data/processed/ub_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 6.12 seconds\n",
      "inferencing train set\n",
      "inference time: 10.21 seconds\n",
      "inferencing test set\n",
      "inference time: 3.55 seconds\n",
      "training\n",
      "training time: 5.38 seconds\n",
      "inferencing train set\n",
      "inference time: 7.01 seconds\n",
      "inferencing test set\n",
      "inference time: 6.88 seconds\n",
      "training\n",
      "training time: 4.42 seconds\n",
      "inferencing train set\n",
      "inference time: 3.89 seconds\n",
      "inferencing test set\n",
      "inference time: 9.7 seconds\n",
      "CPU times: user 52.3 s, sys: 1.7 s, total: 54 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ib_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ib_CF_res = ib_CF_res.append(i)\n",
    "ib_CF_res = ib_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.847614</td>\n",
       "      <td>0.868404</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.727914</td>\n",
       "      <td>0.711738</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.919556</td>\n",
       "      <td>0.622493</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.895520</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.728472</td>\n",
       "      <td>0.702394</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.883137</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.942725</td>\n",
       "      <td>0.960093</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.715264</td>\n",
       "      <td>0.683886</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.817567</td>\n",
       "      <td>0.881841</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.847614  0.868404  0.75_0.25\n",
       "accuracy    0.727914  0.711738  0.75_0.25\n",
       "coverage_2  0.919556  0.622493  0.75_0.25\n",
       "rmse        0.867596  0.895520    0.5_0.5\n",
       "accuracy    0.728472  0.702394    0.5_0.5\n",
       "coverage_2  0.883137  0.840664    0.5_0.5\n",
       "rmse        0.942725  0.960093  0.25_0.75\n",
       "accuracy    0.715264  0.683886  0.25_0.75\n",
       "coverage_2  0.817567  0.881841  0.25_0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_CF_res.to_csv('../data/processed/ib_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Matrix Factorization Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Cross_validate_als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"regParam\": [0.01, 0.05, 0.1, 0.15],\n",
    "    \"rank\": [10, 50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "cf = cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:31<00:00, 40.59s/it]\n",
      "100%|██████████| 20/20 [12:29<00:00, 37.48s/it]\n",
      "100%|██████████| 20/20 [09:07<00:00, 27.37s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = Cross_validate_als(training = train,\n",
    "                            test= test,\n",
    "                            valid_ratio = .1,\n",
    "                            regParam = parameters['regParam'],\n",
    "                            rank = parameters['rank'],\n",
    "                            seed = 0,\n",
    "                            evaluators = list(evaluators.values()))\n",
    "    result.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_parameter_tuning = pd.DataFrame(columns = ['rmse', 'accuracy', 'converage_k'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_parameter_tuning = als_parameter_tuning.append(i)\n",
    "als_parameter_tuning = als_parameter_tuning.dropna()\n",
    "als_parameter_tuning.index.name = '(regParam, rank)'\n",
    "als_parameter_tuning.to_csv('../data/processed/als_parameter_tuning.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameter for each split and metric is\n",
      "best param for accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: rmse, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for rmse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for coverage_k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'the best parameter for each split and metric is')\n",
    "print(f'best param for accuracy')\n",
    "display(als_parameter_tuning.groupby('split').rmse.apply(lambda x: x.idxmin()))\n",
    "print(f'best param for rmse')\n",
    "display(als_parameter_tuning.groupby('split').accuracy.apply(lambda x: x.idxmax()))\n",
    "print(f'best param for coverage_k')\n",
    "display(als_parameter_tuning.groupby('split').accuracy.apply(lambda x: x.idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the best parameter regParam = .15, rank = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_based import Als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 1.89 seconds\n",
      "inferencing train set\n",
      "inference time: 0.01 seconds\n",
      "inferencing test set\n",
      "inference time: 0.01 seconds\n",
      "training\n",
      "training time: 1.71 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.01 seconds\n",
      "training\n",
      "training time: 1.6 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.02 seconds\n",
      "CPU times: user 94.5 ms, sys: 32.5 ms, total: 127 ms\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "als_cf_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_cf_res = als_cf_res.append(i)\n",
    "als_cf_res = als_cf_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_cf_res.to_csv('../data/processed/als_result.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.706560</td>\n",
       "      <td>0.876594</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.752026</td>\n",
       "      <td>0.658994</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.915053</td>\n",
       "      <td>0.591130</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>0.915222</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.783940</td>\n",
       "      <td>0.643931</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.876836</td>\n",
       "      <td>0.792291</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.540238</td>\n",
       "      <td>1.009128</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.829883</td>\n",
       "      <td>0.606153</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.740869</td>\n",
       "      <td>0.834118</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.706560  0.876594  0.75_0.25\n",
       "accuracy    0.752026  0.658994  0.75_0.25\n",
       "coverage_2  0.915053  0.591130  0.75_0.25\n",
       "rmse        0.649651  0.915222    0.5_0.5\n",
       "accuracy    0.783940  0.643931    0.5_0.5\n",
       "coverage_2  0.876836  0.792291    0.5_0.5\n",
       "rmse        0.540238  1.009128  0.25_0.75\n",
       "accuracy    0.829883  0.606153  0.25_0.75\n",
       "coverage_2  0.740869  0.834118  0.25_0.75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_cf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalization",
   "language": "python",
   "name": "personalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
