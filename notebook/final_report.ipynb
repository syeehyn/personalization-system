{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IEOR 4571 Fall 2020 Homework2 Report**\n",
    "\n",
    "\n",
    "- Hu, Bo (uni: bh2569)\n",
    "- Qin, Rui (uni: rq217)\n",
    "- Yuan, Shuibenyang (uni: sy2938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo how did we sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import loading, Spark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI address http://127.0.0.1:4040\n"
     ]
    }
   ],
   "source": [
    "# create spark session\n",
    "spark = Spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data from '/data/raw/sample.csv'\n",
    "datas = loading(spark, '../data/raw')\n",
    "sample = datas['sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            number of data points in the sample: 444289,\n",
      "            number of unique users in the sample: 20000,\n",
      "            number of unique movies in the sample: 1000,\n",
      "            mean of number of movies a user rated:22.21445,\n",
      "            mean of number of users a movie be rated: 444.289,\n",
      "            average rating: 3.562069958968149,\n",
      "            standard deviation of rating: 1.0467842419621054,\n",
      "            average rating by user: 3.685826601448731,\n",
      "            standard deviation of rating by user mean: 0.5225862364055156,\n",
      "            average rating by movie: 3.290922029378176,\n",
      "            standard deviation of rating by movie mean: 0.5133362661920545\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "            number of data points in the sample: {sample.count()},\n",
    "            number of unique users in the sample: {sample.select('userId').distinct().count()},\n",
    "            number of unique movies in the sample: {sample.select('movieId').distinct().count()},\n",
    "            mean of number of movies a user rated:{sample.groupby('userId').agg(F.count('movieId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            mean of number of users a movie be rated: {sample.groupby('movieId').agg(F.count('userId').alias('cnt')).select(F.mean('cnt')).collect()[0][0]},\n",
    "            average rating: {sample.select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating: {sample.select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by user: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by user mean: {sample.groupby('userId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]},\n",
    "            average rating by movie: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.mean('rating')).collect()[0][0]},\n",
    "            standard deviation of rating by movie mean: {sample.groupby('movieId').agg(F.mean('rating').alias('rating')).select(F.stddev('rating')).collect()[0][0]}\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Evaluator, Cross_validate_als\n",
    "from src.model_based import Als\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = loading(spark, '../data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_0.5_0.5', 'train_0.25_0.75', 'test_0.5_0.5', 'test_0.25_0.75', 'train_0.75_0.25', 'test_0.75_0.25']\n"
     ]
    }
   ],
   "source": [
    "print(list(splits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build evaluation pipeline\n",
    "def evaluate(train, test, evaluators, model):\n",
    "    print('training')\n",
    "    start = time.time()\n",
    "    model.fit(train)\n",
    "    end = time.time()\n",
    "    print(f'training time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing train set')\n",
    "    start = time.time()\n",
    "    train_pred = model.predict(train)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    print('inferencing test set')\n",
    "    start = time.time()\n",
    "    test_pred = model.predict(test)\n",
    "    end = time.time()\n",
    "    print(f'inference time: {round(end - start, 2)} seconds')\n",
    "    res = pd.DataFrame(np.zeros((len(evaluators),2)), columns = ['train', 'test'], index = evaluators.keys())\n",
    "    for eva in evaluators.keys():\n",
    "        res.loc[eva, 'train'] = evaluators[eva].evaluate(train_pred)\n",
    "        res.loc[eva, 'test'] = evaluators[eva].evaluate(test_pred)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {'rmse': Evaluator(metrics = 'rmse'), \n",
    "              'accuracy': Evaluator(metrics = 'accuracy'), \n",
    "              'coverage_2': Evaluator(metrics = 'converage_k', \n",
    "                                       ratingCol='rating', \n",
    "                                       predCol='prediction', \n",
    "                                       idCol='userId', \n",
    "                                       k=2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baseline import Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 0.12 seconds\n",
      "inferencing train set\n",
      "inference time: 0.05 seconds\n",
      "inferencing test set\n",
      "inference time: 0.04 seconds\n",
      "training\n",
      "training time: 0.03 seconds\n",
      "inferencing train set\n",
      "inference time: 0.03 seconds\n",
      "inferencing test set\n",
      "inference time: 0.03 seconds\n",
      "training\n",
      "training time: 0.03 seconds\n",
      "inferencing train set\n",
      "inference time: 0.03 seconds\n",
      "inferencing test set\n",
      "inference time: 0.03 seconds\n",
      "CPU times: user 102 ms, sys: 36 ms, total: 138 ms\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, model)\n",
    "    result.append(res)\n",
    "baseline_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    baseline_res = baseline_res.append(i)\n",
    "baseline_res = baseline_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_res.to_csv('../data/processed/baseline_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.871576</td>\n",
       "      <td>0.913753</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.859188</td>\n",
       "      <td>0.831457</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.991162</td>\n",
       "      <td>0.716097</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.858781</td>\n",
       "      <td>0.922455</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.865157</td>\n",
       "      <td>0.832447</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.832999</td>\n",
       "      <td>0.937656</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.874522</td>\n",
       "      <td>0.829091</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.911197</td>\n",
       "      <td>0.981760</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.871576  0.913753  0.75_0.25\n",
       "accuracy    0.859188  0.831457  0.75_0.25\n",
       "coverage_2  0.991162  0.716097  0.75_0.25\n",
       "rmse        0.858781  0.922455    0.5_0.5\n",
       "accuracy    0.865157  0.832447    0.5_0.5\n",
       "coverage_2  0.979832  0.962492    0.5_0.5\n",
       "rmse        0.832999  0.937656  0.25_0.75\n",
       "accuracy    0.874522  0.829091  0.25_0.75\n",
       "coverage_2  0.911197  0.981760  0.25_0.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.memory_based import Memory_based_CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 38.95 seconds\n",
      "inferencing train set\n",
      "inference time: 10.73 seconds\n",
      "inferencing test set\n",
      "inference time: 3.67 seconds\n",
      "training\n",
      "training time: 34.61 seconds\n",
      "inferencing train set\n",
      "inference time: 7.39 seconds\n",
      "inferencing test set\n",
      "inference time: 7.17 seconds\n",
      "training\n",
      "training time: 31.48 seconds\n",
      "inferencing train set\n",
      "inference time: 4.45 seconds\n",
      "inferencing test set\n",
      "inference time: 10.67 seconds\n",
      "CPU times: user 3min 52s, sys: 31.8 s, total: 4min 24s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ub_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ub_CF_res = ub_CF_res.append(i)\n",
    "ub_CF_res = ub_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.821108</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.842982</td>\n",
       "      <td>0.803747</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.708690</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.808453</td>\n",
       "      <td>0.921639</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.851055</td>\n",
       "      <td>0.797801</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.969546</td>\n",
       "      <td>0.945709</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.784599</td>\n",
       "      <td>0.980886</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.861927</td>\n",
       "      <td>0.779768</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.910176</td>\n",
       "      <td>0.967936</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.821108  0.894580  0.75_0.25\n",
       "accuracy    0.842982  0.803747  0.75_0.25\n",
       "coverage_2  0.983591  0.708690  0.75_0.25\n",
       "rmse        0.808453  0.921639    0.5_0.5\n",
       "accuracy    0.851055  0.797801    0.5_0.5\n",
       "coverage_2  0.969546  0.945709    0.5_0.5\n",
       "rmse        0.784599  0.980886  0.25_0.75\n",
       "accuracy    0.861927  0.779768  0.25_0.75\n",
       "coverage_2  0.910176  0.967936  0.25_0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_CF_res.to_csv('../data/processed/ub_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Memory_based_CF(spark, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 6.04 seconds\n",
      "inferencing train set\n",
      "inference time: 11.87 seconds\n",
      "inferencing test set\n",
      "inference time: 3.95 seconds\n",
      "training\n",
      "training time: 5.83 seconds\n",
      "inferencing train set\n",
      "inference time: 7.73 seconds\n",
      "inferencing test set\n",
      "inference time: 7.5 seconds\n",
      "training\n",
      "training time: 4.75 seconds\n",
      "inferencing train set\n",
      "inference time: 4.16 seconds\n",
      "inferencing test set\n",
      "inference time: 10.59 seconds\n",
      "CPU times: user 56.4 s, sys: 2.1 s, total: 58.5 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "ib_CF_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    ib_CF_res = ib_CF_res.append(i)\n",
    "ib_CF_res = ib_CF_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.847614</td>\n",
       "      <td>0.868404</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.837997</td>\n",
       "      <td>0.811680</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.977120</td>\n",
       "      <td>0.705143</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.895520</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.837147</td>\n",
       "      <td>0.807913</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.951262</td>\n",
       "      <td>0.932456</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.942725</td>\n",
       "      <td>0.960093</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.825541</td>\n",
       "      <td>0.793047</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.864011</td>\n",
       "      <td>0.958940</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.847614  0.868404  0.75_0.25\n",
       "accuracy    0.837997  0.811680  0.75_0.25\n",
       "coverage_2  0.977120  0.705143  0.75_0.25\n",
       "rmse        0.867596  0.895520    0.5_0.5\n",
       "accuracy    0.837147  0.807913    0.5_0.5\n",
       "coverage_2  0.951262  0.932456    0.5_0.5\n",
       "rmse        0.942725  0.960093  0.25_0.75\n",
       "accuracy    0.825541  0.793047  0.25_0.75\n",
       "coverage_2  0.864011  0.958940  0.25_0.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib_CF_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_CF_res.to_csv('../data/processed/ib_cf_res.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Matrix Factorization Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import Cross_validate_als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"regParam\": [0.01, 0.05, 0.1, 0.15],\n",
    "    \"rank\": [10, 50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "cf = cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [13:31<00:00, 40.59s/it]\n",
      "100%|██████████| 20/20 [12:29<00:00, 37.48s/it]\n",
      "100%|██████████| 20/20 [09:07<00:00, 27.37s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = Cross_validate_als(training = train,\n",
    "                            test= test,\n",
    "                            valid_ratio = .1,\n",
    "                            regParam = parameters['regParam'],\n",
    "                            rank = parameters['rank'],\n",
    "                            seed = 0,\n",
    "                            evaluators = list(evaluators.values()))\n",
    "    result.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_parameter_tuning = pd.DataFrame(columns = ['rmse', 'accuracy', 'converage_k'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_parameter_tuning = als_parameter_tuning.append(i)\n",
    "als_parameter_tuning = als_parameter_tuning.dropna()\n",
    "als_parameter_tuning.index.name = '(regParam, rank)'\n",
    "als_parameter_tuning.to_csv('../data/processed/als_parameter_tuning.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best parameter for each split and metric is\n",
      "best param for accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: rmse, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for rmse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param for coverage_k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "0.25_0.75    (0.15, 10)\n",
       "0.5_0.5      (0.15, 10)\n",
       "0.75_0.25    (0.15, 10)\n",
       "Name: accuracy, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'the best parameter for each split and metric is')\n",
    "print(f'best param for accuracy')\n",
    "display(als_parameter_tuning.groupby('split').rmse.apply(lambda x: x.idxmin()))\n",
    "print(f'best param for rmse')\n",
    "display(als_parameter_tuning.groupby('split').accuracy.apply(lambda x: x.idxmax()))\n",
    "print(f'best param for coverage_k')\n",
    "display(als_parameter_tuning.groupby('split').accuracy.apply(lambda x: x.idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the best parameter regParam = .15, rank = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_based import Als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Als(userCol='userId',\n",
    "                itemCol='movieId',\n",
    "                ratingCol='rating',\n",
    "                regParam=.15,\n",
    "                seed=0,\n",
    "                rank=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "training time: 3.74 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.02 seconds\n",
      "training\n",
      "training time: 2.01 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.02 seconds\n",
      "training\n",
      "training time: 1.57 seconds\n",
      "inferencing train set\n",
      "inference time: 0.02 seconds\n",
      "inferencing test set\n",
      "inference time: 0.01 seconds\n",
      "CPU times: user 97.2 ms, sys: 33.1 ms, total: 130 ms\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = []\n",
    "for i in ['0.75_0.25', '0.5_0.5', '0.25_0.75']:\n",
    "    train, test = splits['train_' + i], splits['test_' + i]\n",
    "    res = evaluate(train, test, evaluators, cf)\n",
    "    result.append(res)\n",
    "als_cf_res = pd.DataFrame(index=['rmse', 'accuracy', 'coverage_5'], columns = ['train', 'test', 'split'])\n",
    "for i, j in zip(result, ['0.75_0.25', '0.5_0.5', '0.25_0.75']):\n",
    "    i['split'] = j\n",
    "    als_cf_res = als_cf_res.append(i)\n",
    "als_cf_res = als_cf_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_cf_res.to_csv('../data/processed/als_result.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.706560</td>\n",
       "      <td>0.876594</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.845688</td>\n",
       "      <td>0.768591</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.975542</td>\n",
       "      <td>0.692619</td>\n",
       "      <td>0.75_0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.649651</td>\n",
       "      <td>0.915222</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.859147</td>\n",
       "      <td>0.751764</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.945363</td>\n",
       "      <td>0.903569</td>\n",
       "      <td>0.5_0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.540238</td>\n",
       "      <td>1.009128</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.872770</td>\n",
       "      <td>0.705264</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coverage_2</th>\n",
       "      <td>0.845193</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.25_0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train      test      split\n",
       "rmse        0.706560  0.876594  0.75_0.25\n",
       "accuracy    0.845688  0.768591  0.75_0.25\n",
       "coverage_2  0.975542  0.692619  0.75_0.25\n",
       "rmse        0.649651  0.915222    0.5_0.5\n",
       "accuracy    0.859147  0.751764    0.5_0.5\n",
       "coverage_2  0.945363  0.903569    0.5_0.5\n",
       "rmse        0.540238  1.009128  0.25_0.75\n",
       "accuracy    0.872770  0.705264  0.25_0.75\n",
       "coverage_2  0.845193  0.923880  0.25_0.75"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_cf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalization",
   "language": "python",
   "name": "personalization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
